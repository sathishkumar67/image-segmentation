{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import functional as TF\n",
    "from dataclasses import dataclass\n",
    "from __future__ import annotations\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImageDatasetConfig:\n",
    "    foreground_dir: str = \"shoe_dataset/\"\n",
    "    background_dir: str = \"shoe_dataset/bg/\"\n",
    "    mode: str = \"train\"\n",
    "    image_size: int = 256\n",
    "    augment: bool = True\n",
    "    augment_prob: float = 0.5\n",
    "\n",
    "img_ds_config = ImageDatasetConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_ds_config) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.foreground_directory = image_ds_config.foreground_dir\n",
    "        self.background_directory = image_ds_config.background_dir\n",
    "        self.mode = image_ds_config.mode\n",
    "        self.image_size = image_ds_config.image_size\n",
    "        self.augment = image_ds_config.augment\n",
    "        self.augment_prob = image_ds_config.augment_prob\n",
    "        self.rotation_degree = [0, 90, 180, 270]\n",
    "\n",
    "        self.train_images = list(map(lambda x: f\"{self.foreground_directory}train/{x}\", os.listdir(f\"{self.foreground_directory}/train\")))\n",
    "        self.val_images = list(map(lambda x: f\"{self.foreground_directory}val/{x}\", os.listdir(f\"{self.foreground_directory}/val\")))\n",
    "        self.test_images = list(map(lambda x: f\"{self.foreground_directory}test/{x}\", os.listdir(f\"{self.foreground_directory}/test\")))\n",
    "        self.train_background_images = list(map(lambda x: f\"{self.background_directory}train/{x}\", os.listdir(f\"{self.background_directory}/train\")))\n",
    "        self.val_background_images = list(map(lambda x: f\"{self.background_directory}val/{x}\", os.listdir(f\"{self.background_directory}/val\")))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == \"train\":\n",
    "            img_path = self.train_images[index]\n",
    "        elif self.mode == \"val\":\n",
    "            img_path = self.val_images[index]\n",
    "        else:\n",
    "            img_path = self.test_images[index]\n",
    "\n",
    "        print(img_path)\n",
    "        return self.transform_image(img_path, self.augment)\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.mode == \"train\":\n",
    "            return len(self.train_images)\n",
    "        elif self.mode == \"val\":\n",
    "            return len(self.val_images)\n",
    "        else:\n",
    "            return len(self.test_images)\n",
    "    \n",
    "    def transform_image(self, img_path: str, augment: bool):\n",
    "        image_alpha = Image.open(img_path)\n",
    "        assert str(image_alpha.mode) == 'RGBA'\n",
    "        x, y = image_alpha.size\n",
    "        aspect_ratio = y / x\n",
    "        ch_r, ch_g, ch_b, ch_a = image_alpha.split()\n",
    "        img = Image.merge('RGB', (ch_r, ch_g, ch_b))\n",
    "        mask = ch_a\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            bg = Image.open(self.train_background_images[random.randint(0, len(self.train_background_images)-1)])\n",
    "            bg = bg.resize(img.size)\n",
    "            bg.paste(img, mask=mask)\n",
    "        else:\n",
    "            bg = Image.open(self.val_background_images[random.randint(0, len(self.val_background_images)-1)])\n",
    "            bg = bg.resize(img.size)\n",
    "            bg.paste(img, mask=mask)\n",
    "\n",
    "        img = bg\n",
    "            \n",
    "        if augment and random.random() < self.augment_prob:\n",
    "            transform = list()\n",
    "            resize_range = random.randint(300, 320)\n",
    "            transform.append(T.Resize((int(resize_range * aspect_ratio), resize_range)))\n",
    "            rot_deg = self.rotation_degree[random.randint(0, 3)]\n",
    "            if rot_deg == 90 or rot_deg == 270:\n",
    "                aspect_ratio = 1 / aspect_ratio\n",
    "            transform.append(T.RandomRotation((rot_deg, rot_deg)))\n",
    "            rot_range = random.randint(-10, 10)\n",
    "            transform.append(T.RandomRotation((rot_range, rot_range)))\n",
    "            crop_range = random.randint(270, 300)\n",
    "            transform.append(T.CenterCrop((int(crop_range * aspect_ratio), crop_range)))\n",
    "            transform = T.Compose(transform)\n",
    "\n",
    "            img = transform(img)\n",
    "            mask = transform(mask)\n",
    "\n",
    "            transform = T.ColorJitter(brightness=0.2, contrast=0.2, hue=0.2)\n",
    "\n",
    "            img = transform(img)\n",
    "\n",
    "            if random.random() < 0.5:\n",
    "                img = TF.hflip(img)\n",
    "                mask = TF.hflip(mask)\n",
    "            \n",
    "            if random.random() < 0.5:\n",
    "                img = TF.vflip(img)\n",
    "                mask = TF.vflip(mask)\n",
    "            \n",
    "        transform = list()\n",
    "        transform.append(T.Resize((self.image_size, self.image_size)))\n",
    "        transform.append(T.ToTensor())\n",
    "        transform = T.Compose(transform)\n",
    "\n",
    "        img = transform(img)\n",
    "        mask = transform(mask)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(img_ds_config)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoe_dataset/train/480.png\n",
      "shoe_dataset/train/412.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/88.png\n",
      "shoe_dataset/train/221.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/603.png\n",
      "shoe_dataset/train/134.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/213.png\n",
      "shoe_dataset/train/288.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/598.png\n",
      "shoe_dataset/train/132.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/612.png\n",
      "shoe_dataset/train/619.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/311.png\n",
      "shoe_dataset/train/54.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/259.png\n",
      "shoe_dataset/train/491.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/236.png\n",
      "shoe_dataset/train/116.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/466.png\n",
      "shoe_dataset/train/249.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/532.png\n",
      "shoe_dataset/train/514.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/269.png\n",
      "shoe_dataset/train/105.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/535.png\n",
      "shoe_dataset/train/536.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/55.png\n",
      "shoe_dataset/train/423.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/359.png\n",
      "shoe_dataset/train/9.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/166.png\n",
      "shoe_dataset/train/585.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/280.png\n",
      "shoe_dataset/train/583.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/373.png\n",
      "shoe_dataset/train/366.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/455.png\n",
      "shoe_dataset/train/21.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/283.png\n",
      "shoe_dataset/train/424.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/43.png\n",
      "shoe_dataset/train/600.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/289.png\n",
      "shoe_dataset/train/224.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/501.png\n",
      "shoe_dataset/train/433.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/398.png\n",
      "shoe_dataset/train/375.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/552.png\n",
      "shoe_dataset/train/608.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/555.png\n",
      "shoe_dataset/train/467.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/108.png\n",
      "shoe_dataset/train/322.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/588.png\n",
      "shoe_dataset/train/571.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/48.png\n",
      "shoe_dataset/train/16.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/49.png\n",
      "shoe_dataset/train/544.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/100.png\n",
      "shoe_dataset/train/293.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/92.png\n",
      "shoe_dataset/train/348.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/315.png\n",
      "shoe_dataset/train/111.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/299.png\n",
      "shoe_dataset/train/593.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/524.png\n",
      "shoe_dataset/train/400.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/353.png\n",
      "shoe_dataset/train/158.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/109.png\n",
      "shoe_dataset/train/262.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/610.png\n",
      "shoe_dataset/train/397.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/558.png\n",
      "shoe_dataset/train/65.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/192.png\n",
      "shoe_dataset/train/263.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/300.png\n",
      "shoe_dataset/train/507.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/271.png\n",
      "shoe_dataset/train/408.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/273.png\n",
      "shoe_dataset/train/541.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/355.png\n",
      "shoe_dataset/train/547.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/625.png\n",
      "shoe_dataset/train/528.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/495.png\n",
      "shoe_dataset/train/35.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/452.png\n",
      "shoe_dataset/train/384.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/562.png\n",
      "shoe_dataset/train/117.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/20.png\n",
      "shoe_dataset/train/380.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/407.png\n",
      "shoe_dataset/train/168.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/256.png\n",
      "shoe_dataset/train/12.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/151.png\n",
      "shoe_dataset/train/450.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/67.png\n",
      "shoe_dataset/train/319.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/546.png\n",
      "shoe_dataset/train/357.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/377.png\n",
      "shoe_dataset/train/24.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/622.png\n",
      "shoe_dataset/train/234.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/1.png\n",
      "shoe_dataset/train/393.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/37.png\n",
      "shoe_dataset/train/320.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/321.png\n",
      "shoe_dataset/train/301.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/237.png\n",
      "shoe_dataset/train/581.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/325.png\n",
      "shoe_dataset/train/616.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/444.png\n",
      "shoe_dataset/train/110.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/139.png\n",
      "shoe_dataset/train/525.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/295.png\n",
      "shoe_dataset/train/266.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/371.png\n",
      "shoe_dataset/train/317.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/302.png\n",
      "shoe_dataset/train/209.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/415.png\n",
      "shoe_dataset/train/141.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/332.png\n",
      "shoe_dataset/train/218.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/265.png\n",
      "shoe_dataset/train/157.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/270.png\n",
      "shoe_dataset/train/297.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/38.png\n",
      "shoe_dataset/train/604.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/413.png\n",
      "shoe_dataset/train/242.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/47.png\n",
      "shoe_dataset/train/72.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/184.png\n",
      "shoe_dataset/train/416.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/178.png\n",
      "shoe_dataset/train/13.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/505.png\n",
      "shoe_dataset/train/549.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/137.png\n",
      "shoe_dataset/train/516.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/417.png\n",
      "shoe_dataset/train/19.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/626.png\n",
      "shoe_dataset/train/287.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/145.png\n",
      "shoe_dataset/train/318.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/414.png\n",
      "shoe_dataset/train/261.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/8.png\n",
      "shoe_dataset/train/298.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/592.png\n",
      "shoe_dataset/train/82.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/91.png\n",
      "shoe_dataset/train/99.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/59.png\n",
      "shoe_dataset/train/205.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/120.png\n",
      "shoe_dataset/train/559.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/360.png\n",
      "shoe_dataset/train/451.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/531.png\n",
      "shoe_dataset/train/512.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/539.png\n",
      "shoe_dataset/train/448.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/212.png\n",
      "shoe_dataset/train/181.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/563.png\n",
      "shoe_dataset/train/75.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/97.png\n",
      "shoe_dataset/train/40.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/164.png\n",
      "shoe_dataset/train/235.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/594.png\n",
      "shoe_dataset/train/382.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/510.png\n",
      "shoe_dataset/train/386.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/39.png\n",
      "shoe_dataset/train/362.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/542.png\n",
      "shoe_dataset/train/118.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/365.png\n",
      "shoe_dataset/train/618.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/479.png\n",
      "shoe_dataset/train/331.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/57.png\n",
      "shoe_dataset/train/142.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/437.png\n",
      "shoe_dataset/train/123.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/195.png\n",
      "shoe_dataset/train/418.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/468.png\n",
      "shoe_dataset/train/278.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/232.png\n",
      "shoe_dataset/train/508.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/605.png\n",
      "shoe_dataset/train/303.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/310.png\n",
      "shoe_dataset/train/277.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/435.png\n",
      "shoe_dataset/train/350.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/347.png\n",
      "shoe_dataset/train/602.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/204.png\n",
      "shoe_dataset/train/529.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/606.png\n",
      "shoe_dataset/train/70.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/406.png\n",
      "shoe_dataset/train/196.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/27.png\n",
      "shoe_dataset/train/340.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/28.png\n",
      "shoe_dataset/train/246.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/409.png\n",
      "shoe_dataset/train/133.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/150.png\n",
      "shoe_dataset/train/401.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/106.png\n",
      "shoe_dataset/train/294.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/460.png\n",
      "shoe_dataset/train/396.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/251.png\n",
      "shoe_dataset/train/225.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/140.png\n",
      "shoe_dataset/train/22.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/190.png\n",
      "shoe_dataset/train/422.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/445.png\n",
      "shoe_dataset/train/200.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/64.png\n",
      "shoe_dataset/train/381.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/126.png\n",
      "shoe_dataset/train/449.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/264.png\n",
      "shoe_dataset/train/372.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/238.png\n",
      "shoe_dataset/train/589.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/307.png\n",
      "shoe_dataset/train/570.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/215.png\n",
      "shoe_dataset/train/26.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/475.png\n",
      "shoe_dataset/train/279.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/411.png\n",
      "shoe_dataset/train/576.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/586.png\n",
      "shoe_dataset/train/248.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/369.png\n",
      "shoe_dataset/train/217.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/503.png\n",
      "shoe_dataset/train/156.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/226.png\n",
      "shoe_dataset/train/356.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/175.png\n",
      "shoe_dataset/train/84.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/73.png\n",
      "shoe_dataset/train/623.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/470.png\n",
      "shoe_dataset/train/312.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/590.png\n",
      "shoe_dataset/train/74.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/30.png\n",
      "shoe_dataset/train/171.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/18.png\n",
      "shoe_dataset/train/227.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/551.png\n",
      "shoe_dataset/train/391.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/548.png\n",
      "shoe_dataset/train/540.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/439.png\n",
      "shoe_dataset/train/89.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/42.png\n",
      "shoe_dataset/train/471.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/534.png\n",
      "shoe_dataset/train/394.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/4.png\n",
      "shoe_dataset/train/131.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/329.png\n",
      "shoe_dataset/train/228.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/170.png\n",
      "shoe_dataset/train/392.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/23.png\n",
      "shoe_dataset/train/163.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/599.png\n",
      "shoe_dataset/train/569.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/587.png\n",
      "shoe_dataset/train/486.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/282.png\n",
      "shoe_dataset/train/165.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/214.png\n",
      "shoe_dataset/train/53.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/429.png\n",
      "shoe_dataset/train/537.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/257.png\n",
      "shoe_dataset/train/420.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/352.png\n",
      "shoe_dataset/train/442.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/180.png\n",
      "shoe_dataset/train/346.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/136.png\n",
      "shoe_dataset/train/243.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/438.png\n",
      "shoe_dataset/train/187.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/550.png\n",
      "shoe_dataset/train/554.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/78.png\n",
      "shoe_dataset/train/478.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/582.png\n",
      "shoe_dataset/train/378.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/388.png\n",
      "shoe_dataset/train/399.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/364.png\n",
      "shoe_dataset/train/127.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/584.png\n",
      "shoe_dataset/train/104.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/431.png\n",
      "shoe_dataset/train/121.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/31.png\n",
      "shoe_dataset/train/484.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/179.png\n",
      "shoe_dataset/train/220.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/613.png\n",
      "shoe_dataset/train/203.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/383.png\n",
      "shoe_dataset/train/358.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/86.png\n",
      "shoe_dataset/train/68.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/169.png\n",
      "shoe_dataset/train/96.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/41.png\n",
      "shoe_dataset/train/254.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/453.png\n",
      "shoe_dataset/train/14.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/208.png\n",
      "shoe_dataset/train/419.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/629.png\n",
      "shoe_dataset/train/496.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/565.png\n",
      "shoe_dataset/train/176.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/490.png\n",
      "shoe_dataset/train/233.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/430.png\n",
      "shoe_dataset/train/103.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/62.png\n",
      "shoe_dataset/train/223.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/2.png\n",
      "shoe_dataset/train/10.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/185.png\n",
      "shoe_dataset/train/314.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/284.png\n",
      "shoe_dataset/train/83.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/519.png\n",
      "shoe_dataset/train/285.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/342.png\n",
      "shoe_dataset/train/434.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/611.png\n",
      "shoe_dataset/train/561.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/351.png\n",
      "shoe_dataset/train/370.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/405.png\n",
      "shoe_dataset/train/336.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/580.png\n",
      "shoe_dataset/train/63.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/578.png\n",
      "shoe_dataset/train/469.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/240.png\n",
      "shoe_dataset/train/304.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/403.png\n",
      "shoe_dataset/train/402.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/11.png\n",
      "shoe_dataset/train/337.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/7.png\n",
      "shoe_dataset/train/530.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/506.png\n",
      "shoe_dataset/train/128.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/517.png\n",
      "shoe_dataset/train/390.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/624.png\n",
      "shoe_dataset/train/268.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/241.png\n",
      "shoe_dataset/train/545.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/17.png\n",
      "shoe_dataset/train/607.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/520.png\n",
      "shoe_dataset/train/135.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/596.png\n",
      "shoe_dataset/train/327.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/313.png\n",
      "shoe_dataset/train/404.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/76.png\n",
      "shoe_dataset/train/498.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/440.png\n",
      "shoe_dataset/train/472.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/274.png\n",
      "shoe_dataset/train/597.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/476.png\n",
      "shoe_dataset/train/138.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/518.png\n",
      "shoe_dataset/train/395.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/443.png\n",
      "shoe_dataset/train/601.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/3.png\n",
      "shoe_dataset/train/102.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/461.png\n",
      "shoe_dataset/train/60.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/44.png\n",
      "shoe_dataset/train/345.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/173.png\n",
      "shoe_dataset/train/354.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/231.png\n",
      "shoe_dataset/train/620.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/32.png\n",
      "shoe_dataset/train/50.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/522.png\n",
      "shoe_dataset/train/258.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/160.png\n",
      "shoe_dataset/train/473.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/95.png\n",
      "shoe_dataset/train/52.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/385.png\n",
      "shoe_dataset/train/202.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/427.png\n",
      "shoe_dataset/train/260.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/487.png\n",
      "shoe_dataset/train/77.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/182.png\n",
      "shoe_dataset/train/219.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/428.png\n",
      "shoe_dataset/train/376.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/152.png\n",
      "shoe_dataset/train/344.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/361.png\n",
      "shoe_dataset/train/255.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/87.png\n",
      "shoe_dataset/train/574.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/538.png\n",
      "shoe_dataset/train/343.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/85.png\n",
      "shoe_dataset/train/389.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/272.png\n",
      "shoe_dataset/train/474.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/368.png\n",
      "shoe_dataset/train/29.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/341.png\n",
      "shoe_dataset/train/500.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/207.png\n",
      "shoe_dataset/train/330.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/211.png\n",
      "shoe_dataset/train/25.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/194.png\n",
      "shoe_dataset/train/193.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/572.png\n",
      "shoe_dataset/train/252.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/296.png\n",
      "shoe_dataset/train/333.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/482.png\n",
      "shoe_dataset/train/511.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/326.png\n",
      "shoe_dataset/train/410.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/36.png\n",
      "shoe_dataset/train/130.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/462.png\n",
      "shoe_dataset/train/210.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/316.png\n",
      "shoe_dataset/train/436.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/306.png\n",
      "shoe_dataset/train/577.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/573.png\n",
      "shoe_dataset/train/198.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/275.png\n",
      "shoe_dataset/train/425.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/101.png\n",
      "shoe_dataset/train/328.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/167.png\n",
      "shoe_dataset/train/174.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/334.png\n",
      "shoe_dataset/train/564.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/617.png\n",
      "shoe_dataset/train/493.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/6.png\n",
      "shoe_dataset/train/107.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/93.png\n",
      "shoe_dataset/train/66.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/146.png\n",
      "shoe_dataset/train/98.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/533.png\n",
      "shoe_dataset/train/477.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/61.png\n",
      "shoe_dataset/train/34.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/186.png\n",
      "shoe_dataset/train/492.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/291.png\n",
      "shoe_dataset/train/454.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/153.png\n",
      "shoe_dataset/train/124.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/129.png\n",
      "shoe_dataset/train/115.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/15.png\n",
      "shoe_dataset/train/229.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/627.png\n",
      "shoe_dataset/train/222.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/143.png\n",
      "shoe_dataset/train/567.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/483.png\n",
      "shoe_dataset/train/58.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/267.png\n",
      "shoe_dataset/train/556.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/290.png\n",
      "shoe_dataset/train/51.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/71.png\n",
      "shoe_dataset/train/363.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/543.png\n",
      "shoe_dataset/train/502.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/441.png\n",
      "shoe_dataset/train/614.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/33.png\n",
      "shoe_dataset/train/147.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/162.png\n",
      "shoe_dataset/train/488.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/239.png\n",
      "shoe_dataset/train/189.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/125.png\n",
      "shoe_dataset/train/432.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/523.png\n",
      "shoe_dataset/train/497.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/553.png\n",
      "shoe_dataset/train/155.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/112.png\n",
      "shoe_dataset/train/191.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/5.png\n",
      "shoe_dataset/train/247.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/615.png\n",
      "shoe_dataset/train/446.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/465.png\n",
      "shoe_dataset/train/579.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/335.png\n",
      "shoe_dataset/train/421.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/94.png\n",
      "shoe_dataset/train/609.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/149.png\n",
      "shoe_dataset/train/122.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/560.png\n",
      "shoe_dataset/train/489.png\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 1, 256, 256])\n",
      "shoe_dataset/train/113.png\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "image file is truncated (0 bytes not processed)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[84], line 28\u001b[0m, in \u001b[0;36mImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     25\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_images[index]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(img_path)\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[84], line 43\u001b[0m, in \u001b[0;36mImageDataset.transform_image\u001b[1;34m(self, img_path, augment)\u001b[0m\n\u001b[0;32m     41\u001b[0m x, y \u001b[38;5;241m=\u001b[39m image_alpha\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m     42\u001b[0m aspect_ratio \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m/\u001b[39m x\n\u001b[1;32m---> 43\u001b[0m ch_r, ch_g, ch_b, ch_a \u001b[38;5;241m=\u001b[39m \u001b[43mimage_alpha\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mmerge(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m, (ch_r, ch_g, ch_b))\n\u001b[0;32m     45\u001b[0m mask \u001b[38;5;241m=\u001b[39m ch_a\n",
      "File \u001b[1;32mc:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\PIL\\Image.py:2639\u001b[0m, in \u001b[0;36mImage.split\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Image, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m   2626\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2627\u001b[0m \u001b[38;5;124;03m    Split this image into individual bands. This method returns a\u001b[39;00m\n\u001b[0;32m   2628\u001b[0m \u001b[38;5;124;03m    tuple of individual image bands from an image. For example,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2636\u001b[0m \u001b[38;5;124;03m    :returns: A tuple containing bands.\u001b[39;00m\n\u001b[0;32m   2637\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2639\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2640\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39mbands \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2641\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(),)\n",
      "File \u001b[1;32mc:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\PIL\\ImageFile.py:290\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    287\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage file is truncated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(b)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes not processed)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    289\u001b[0m         )\n\u001b[1;32m--> 290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m    293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n",
      "\u001b[1;31mOSError\u001b[0m: image file is truncated (0 bytes not processed)"
     ]
    }
   ],
   "source": [
    "for img, mask in train_dataloader:\n",
    "    print(img.shape)\n",
    "    print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
