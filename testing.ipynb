{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import functional as TF\n",
    "from dataclasses import dataclass\n",
    "from __future__ import annotations\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImageDatasetConfig:\n",
    "    foreground_dir: str = \"shoe_dataset/\"\n",
    "    background_dir: str = \"shoe_dataset/bg/\"\n",
    "    mode: str = \"train\"\n",
    "    image_size: int = 256\n",
    "    augment: bool = True\n",
    "    augment_prob: float = 0.5\n",
    "\n",
    "img_ds_config = ImageDatasetConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_ds_config) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.foreground_directory = image_ds_config.foreground_dir\n",
    "        self.background_directory = image_ds_config.background_dir\n",
    "        self.mode = image_ds_config.mode\n",
    "        self.image_size = image_ds_config.image_size\n",
    "        self.augment = image_ds_config.augment\n",
    "        self.augment_prob = image_ds_config.augment_prob\n",
    "        self.rotation_degree = [0, 90, 180, 270]\n",
    "\n",
    "        self.train_images = list(map(lambda x: f\"{self.foreground_directory}train/{x}\", os.listdir(f\"{self.foreground_directory}/train\")))\n",
    "        self.val_images = list(map(lambda x: f\"{self.foreground_directory}val/{x}\", os.listdir(f\"{self.foreground_directory}/val\")))\n",
    "        self.test_images = list(map(lambda x: f\"{self.foreground_directory}test/{x}\", os.listdir(f\"{self.foreground_directory}/test\")))\n",
    "        self.train_background_images = list(map(lambda x: f\"{self.background_directory}train/{x}\", os.listdir(f\"{self.background_directory}/train\")))\n",
    "        self.val_background_images = list(map(lambda x: f\"{self.background_directory}val/{x}\", os.listdir(f\"{self.background_directory}/val\")))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == \"train\":\n",
    "            if index == len(self.train_images):\n",
    "                index = 0\n",
    "            img_path = self.train_images[index]\n",
    "        elif self.mode == \"val\":\n",
    "            img_path = self.val_images[index]\n",
    "        else:\n",
    "            img_path = self.test_images[index]\n",
    "\n",
    "        return self.transform_image(img_path, self.augment)\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.mode == \"train\":\n",
    "            return len(self.train_images)\n",
    "        elif self.mode == \"val\":\n",
    "            return len(self.val_images)\n",
    "        else:\n",
    "            return len(self.test_images)\n",
    "    \n",
    "    def transform_image(self, img_path: str, augment: bool):\n",
    "        image_alpha = Image.open(img_path)\n",
    "        assert str(image_alpha.mode) == 'RGBA'\n",
    "        x, y = image_alpha.size\n",
    "        aspect_ratio = y / x\n",
    "        ch_r, ch_g, ch_b, ch_a = image_alpha.split()\n",
    "        img = Image.merge('RGB', (ch_r, ch_g, ch_b))\n",
    "        mask = ch_a\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            bg = Image.open(self.train_background_images[random.randint(0, len(self.train_background_images)-1)])\n",
    "            bg = bg.resize(img.size)\n",
    "            bg.paste(img, mask=mask)\n",
    "        else:\n",
    "            bg = Image.open(self.val_background_images[random.randint(0, len(self.val_background_images)-1)])\n",
    "            bg = bg.resize(img.size)\n",
    "            bg.paste(img, mask=mask)\n",
    "\n",
    "        img = bg\n",
    "            \n",
    "        if augment and random.random() < self.augment_prob:\n",
    "            transform = list()\n",
    "            resize_range = random.randint(300, 320)\n",
    "            transform.append(T.Resize((int(resize_range * aspect_ratio), resize_range)))\n",
    "            rot_deg = self.rotation_degree[random.randint(0, 3)]\n",
    "            if rot_deg == 90 or rot_deg == 270:\n",
    "                aspect_ratio = 1 / aspect_ratio\n",
    "            transform.append(T.RandomRotation((rot_deg, rot_deg)))\n",
    "            rot_range = random.randint(-10, 10)\n",
    "            transform.append(T.RandomRotation((rot_range, rot_range)))\n",
    "            crop_range = random.randint(270, 300)\n",
    "            transform.append(T.CenterCrop((int(crop_range * aspect_ratio), crop_range)))\n",
    "            transform = T.Compose(transform)\n",
    "\n",
    "            img = transform(img)\n",
    "            mask = transform(mask)\n",
    "\n",
    "            transform = T.ColorJitter(brightness=0.2, contrast=0.2, hue=0.2)\n",
    "\n",
    "            img = transform(img)\n",
    "\n",
    "            if random.random() < 0.5:\n",
    "                img = TF.hflip(img)\n",
    "                mask = TF.hflip(mask)\n",
    "            \n",
    "            if random.random() < 0.5:\n",
    "                img = TF.vflip(img)\n",
    "                mask = TF.vflip(mask)\n",
    "            \n",
    "        transform = list()\n",
    "        transform.append(T.Resize((self.image_size, self.image_size)))\n",
    "        transform.append(T.ToTensor())\n",
    "        transform = T.Compose(transform)\n",
    "\n",
    "        img = transform(img)\n",
    "        mask = transform(mask)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(img_ds_config)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "image file is truncated (0 bytes not processed)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[93], line 29\u001b[0m, in \u001b[0;36mImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_images[index]\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[93], line 44\u001b[0m, in \u001b[0;36mImageDataset.transform_image\u001b[1;34m(self, img_path, augment)\u001b[0m\n\u001b[0;32m     42\u001b[0m x, y \u001b[38;5;241m=\u001b[39m image_alpha\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m     43\u001b[0m aspect_ratio \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m/\u001b[39m x\n\u001b[1;32m---> 44\u001b[0m ch_r, ch_g, ch_b, ch_a \u001b[38;5;241m=\u001b[39m \u001b[43mimage_alpha\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mmerge(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m, (ch_r, ch_g, ch_b))\n\u001b[0;32m     46\u001b[0m mask \u001b[38;5;241m=\u001b[39m ch_a\n",
      "File \u001b[1;32mc:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\PIL\\Image.py:2639\u001b[0m, in \u001b[0;36mImage.split\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Image, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m   2626\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2627\u001b[0m \u001b[38;5;124;03m    Split this image into individual bands. This method returns a\u001b[39;00m\n\u001b[0;32m   2628\u001b[0m \u001b[38;5;124;03m    tuple of individual image bands from an image. For example,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2636\u001b[0m \u001b[38;5;124;03m    :returns: A tuple containing bands.\u001b[39;00m\n\u001b[0;32m   2637\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2639\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2640\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39mbands \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2641\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(),)\n",
      "File \u001b[1;32mc:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\PIL\\ImageFile.py:290\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    287\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage file is truncated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(b)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes not processed)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    289\u001b[0m         )\n\u001b[1;32m--> 290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m    293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n",
      "\u001b[1;31mOSError\u001b[0m: image file is truncated (0 bytes not processed)"
     ]
    }
   ],
   "source": [
    "for img, mask in train_dataloader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
