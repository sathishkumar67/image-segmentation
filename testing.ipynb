{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import functional as TF\n",
    "from dataclasses import dataclass\n",
    "from __future__ import annotations\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImageDatasetConfig:\n",
    "    foreground_dir: str = \"shoe_dataset/\"\n",
    "    background_dir: str = \"shoe_dataset/bg/\"\n",
    "    mode: str = \"train\"\n",
    "    image_size: int = 256\n",
    "    augment: bool = True\n",
    "    augment_prob: float = 0.5\n",
    "\n",
    "img_ds_config = ImageDatasetConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_ds_config) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.foreground_directory = image_ds_config.foreground_dir\n",
    "        self.background_directory = image_ds_config.background_dir\n",
    "        self.mode = image_ds_config.mode\n",
    "        self.image_size = image_ds_config.image_size\n",
    "        self.augment = image_ds_config.augment\n",
    "        self.rotation_degree = [0, 90, 180, 270]\n",
    "\n",
    "        self.train_images = list(map(lambda x: f\"{self.foreground_directory}train/{x}\", os.listdir(f\"{self.foreground_directory}/train\")))\n",
    "        self.val_images = list(map(lambda x: f\"{self.foreground_directory}val/{x}\", os.listdir(f\"{self.foreground_directory}/val\")))\n",
    "        self.test_images = list(map(lambda x: f\"{self.foreground_directory}test/{x}\", os.listdir(f\"{self.foreground_directory}/test\")))\n",
    "        self.train_background_images = list(map(lambda x: f\"{self.background_directory}train/{x}\", os.listdir(f\"{self.background_directory}/train\")))\n",
    "        self.val_background_images = list(map(lambda x: f\"{self.background_directory}val/{x}\", os.listdir(f\"{self.background_directory}/val\")))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == \"train\":\n",
    "            img_path = self.train_images[index]\n",
    "        elif self.mode == \"val\":\n",
    "            img_path = self.val_images[index]\n",
    "        else:\n",
    "            img_path = self.test_images[index]\n",
    "\n",
    "        print(img_path)\n",
    "        return self.transform_image(img_path, self.augment)\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.mode == \"train\":\n",
    "            return len(self.train_images)\n",
    "        elif self.mode == \"val\":\n",
    "            return len(self.val_images)\n",
    "        else:\n",
    "            return len(self.test_images)\n",
    "    \n",
    "    def transform_image(self, img_path: str, augment: bool):\n",
    "        image_alpha = Image.open(img_path)\n",
    "        assert str(image_alpha.mode) == 'RGBA'\n",
    "        x, y = image_alpha.size\n",
    "        aspect_ratio = y / x\n",
    "        ch_r, ch_g, ch_b, ch_a = image_alpha.split()\n",
    "        img = Image.merge('RGB', (ch_r, ch_g, ch_b))\n",
    "        mask = ch_a\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            bg = Image.open(self.train_background_images[random.randint(0, len(self.train_background_images)-1)])\n",
    "            bg = bg.resize(img.size)\n",
    "            bg.paste(img, mask=mask)\n",
    "        else:\n",
    "            bg = Image.open(self.val_background_images[random.randint(0, len(self.val_background_images)-1)])\n",
    "            bg = bg.resize(img.size)\n",
    "            bg.paste(img, mask=mask)\n",
    "\n",
    "        img = bg\n",
    "            \n",
    "        if augment and random.random() < self.augment_prob:\n",
    "            transform = list()\n",
    "            resize_range = random.randint(300, 320)\n",
    "            transform.append(T.Resize((int(resize_range * aspect_ratio), resize_range)))\n",
    "            rot_deg = self.rotation_degree[random.randint(0, 3)]\n",
    "            if rot_deg == 90 or rot_deg == 270:\n",
    "                aspect_ratio = 1 / aspect_ratio\n",
    "            transform.append(T.RandomRotation((rot_deg, rot_deg)))\n",
    "            rot_range = random.randint(-10, 10)\n",
    "            transform.append(T.RandomRotation((rot_range, rot_range)))\n",
    "            crop_range = random.randint(270, 300)\n",
    "            transform.append(T.CenterCrop((int(crop_range * aspect_ratio), crop_range)))\n",
    "            transform = T.Compose(transform)\n",
    "\n",
    "            img = transform(img)\n",
    "            mask = transform(mask)\n",
    "\n",
    "            transform = T.ColorJitter(brightness=0.2, contrast=0.2, hue=0.2)\n",
    "\n",
    "            img = transform(img)\n",
    "\n",
    "            if random.random() < 0.5:\n",
    "                img = TF.hflip(img)\n",
    "                mask = TF.hflip(mask)\n",
    "            \n",
    "            if random.random() < 0.5:\n",
    "                img = TF.vflip(img)\n",
    "                mask = TF.vflip(mask)\n",
    "            \n",
    "        transform = list()\n",
    "        transform.append(T.Resize((self.image_size, self.image_size)))\n",
    "        transform.append(T.ToTensor())\n",
    "        transform = T.Compose(transform)\n",
    "\n",
    "        img = transform(img)\n",
    "        mask = transform(mask)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(img_ds_config)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
