{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import functional as TF\n",
    "from dataclasses import dataclass\n",
    "from __future__ import annotations\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from model import UNet\n",
    "from loss_function import BCEwithDiceLoss, BCELoss2d, dice_loss, dice_coeff\n",
    "from data_utils import ImageDatasetConfig, ImageDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from lightning.pytorch import Trainer\n",
    "from schedulefree.adamw_schedulefree import AdamWScheduleFree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_ds_config) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.foreground_directory = image_ds_config.foreground_dir\n",
    "        self.background_directory = image_ds_config.background_dir\n",
    "        self.mode = image_ds_config.mode\n",
    "        self.image_size = image_ds_config.image_size\n",
    "        self.augment = image_ds_config.augment\n",
    "        self.augment_prob = image_ds_config.augment_prob\n",
    "        self.rotation_degree = [0, 90, 180, 270]\n",
    "\n",
    "        # Load file paths lazily when needed\n",
    "        self.image_paths = self._load_image_paths()\n",
    "\n",
    "        # Pre-load background images to avoid repeated I/O operations\n",
    "        self.background_images = self._load_background_images()\n",
    "\n",
    "        # Prepare common transforms\n",
    "        self.base_transform = T.Compose([\n",
    "            T.Resize((self.image_size, self.image_size)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "        \n",
    "\n",
    "    def _load_image_paths(self):\n",
    "        if self.mode == \"train\":\n",
    "            return [os.path.join(self.foreground_directory, \"train\", x) for x in os.listdir(os.path.join(self.foreground_directory, \"train\"))]\n",
    "        elif self.mode == \"val\":\n",
    "            return [os.path.join(self.foreground_directory, \"val\", x) for x in os.listdir(os.path.join(self.foreground_directory, \"val\"))]\n",
    "        else:\n",
    "            return [os.path.join(self.foreground_directory, \"test\", x) for x in os.listdir(os.path.join(self.foreground_directory, \"test\"))]\n",
    "\n",
    "\n",
    "    def _load_background_images(self):\n",
    "        bg_dir = os.path.join(self.background_directory, self.mode)\n",
    "        return [os.path.join(bg_dir, x) for x in os.listdir(bg_dir)]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_paths[index]\n",
    "\n",
    "        # Load and transform image and mask\n",
    "        img, mask = self._load_and_process_image(img_path)\n",
    "\n",
    "        # Apply augmentations if enabled\n",
    "        if self.mode == \"train\" and self.augment and random.random() < self.augment_prob:\n",
    "            img, mask = self._apply_augmentation(img, mask)\n",
    "\n",
    "        # Apply final resizing and convert to tensor\n",
    "        img = self.base_transform(img)\n",
    "        mask = self.base_transform(mask)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def _load_and_process_image(self, img_path: str):\n",
    "        # Load the foreground image with alpha channel\n",
    "        image_alpha = Image.open(img_path)\n",
    "        assert image_alpha.mode == 'RGBA', \"Image should be RGBA\"\n",
    "\n",
    "        img = Image.merge('RGB', image_alpha.split()[:3])\n",
    "        mask = image_alpha.split()[-1]  # Alpha channel as mask\n",
    "\n",
    "        # Select and resize a random background image\n",
    "        bg_img = Image.open(random.choice(self.background_images)).resize(img.size)\n",
    "\n",
    "        # Composite the foreground over the background using the mask\n",
    "        bg_img.paste(img, mask=mask)\n",
    "\n",
    "        return bg_img, mask\n",
    "\n",
    "    def _apply_augmentation(self, img, mask):\n",
    "        \"\"\"Apply the same augmentations to both the image and the mask.\"\"\"\n",
    "        \n",
    "        # Random Rotation\n",
    "        angle = random.uniform(-10, 10)\n",
    "        img = TF.rotate(img, angle)\n",
    "        mask = TF.rotate(mask, angle)\n",
    "\n",
    "        # Random Color Jitter (only applied to img, not mask, since mask is not RGB)\n",
    "        color_jitter = T.ColorJitter(brightness=0.2, contrast=0.2, hue=0.2)\n",
    "        img = color_jitter(img)\n",
    "\n",
    "        # Random Horizontal Flip\n",
    "        if random.random() > 0.5:\n",
    "            img = TF.hflip(img)\n",
    "            mask = TF.hflip(mask)\n",
    "\n",
    "        # Random Vertical Flip\n",
    "        if random.random() > 0.5:\n",
    "            img = TF.vflip(img)\n",
    "            mask = TF.vflip(mask)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImageDatasetConfig:\n",
    "    foreground_dir: str = \"shoe_dataset/\"\n",
    "    background_dir: str = \"shoe_dataset/bg/\"\n",
    "    mode: str = \"train\"\n",
    "    image_size: int = 256\n",
    "    augment: bool = False\n",
    "    augment_prob: float = 0.5\n",
    "\n",
    "img_ds_config = ImageDatasetConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ds_config.augment = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(img_ds_config)\n",
    "img_ds_config.augment = False\n",
    "img_ds_config.mode = \"val\"\n",
    "val_dataset = ImageDataset(img_ds_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SegmentationConfig:\n",
    "    n_channels: int = 3\n",
    "    n_classes: int = 1\n",
    "    alpha: int = 0.5\n",
    "    beta: int = 0.5\n",
    "    smooth: float = 1e-5\n",
    "    lr: float = 3e-4\n",
    "    weight_decay: float = 0.1\n",
    "    batch_size: int = 8\n",
    "    num_workers: int = 4\n",
    "    betas: tuple = (0.9, 0.999)\n",
    "    eps: float = 1e-8\n",
    "    epochs: int = 1\n",
    "    device: str = \"cpu\"\n",
    "\n",
    "seg_config = SegmentationConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=seg_config.batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=seg_config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 28)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(n_channels=seg_config.n_channels, n_classes=seg_config.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationWrapper(L.LightningModule):\n",
    "    def __init__(self, model, config: SegmentationConfig):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.loss_fn = BCEwithDiceLoss(alpha=config.alpha, beta=config.beta, smooth=config.smooth)\n",
    "        self.dice_loss = dice_loss\n",
    "        self.optimizer = self.configure_optimizers()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.model.train()\n",
    "        optimizer = self.optimizers()\n",
    "        optimizer.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        img, mask = batch\n",
    "        output = self.model(img)\n",
    "        loss = self.loss_fn(output, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.model.eval()\n",
    "        optimizer = self.optimizers()\n",
    "        optimizer.eval()\n",
    "\n",
    "        img, mask = batch\n",
    "        output = self.model(img)\n",
    "        loss = self.loss_fn(output, mask)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return AdamWScheduleFree(self.model.parameters(), lr=self.config.lr, betas=self.config.betas, eps=self.config.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_wrapper = SegmentationWrapper(model, seg_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=seg_config.epochs, accelerator=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.fit(segmentation_wrapper, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
